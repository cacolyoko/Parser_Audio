{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import speech_recognition as sr\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = \"Borja\"\n",
    "n_file = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   3%|▎         | 29/1023 [00:00<00:05, 191.01it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in .\\\\audios\\\\Borja_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Extraigo el audio del vídeo\n",
    "\n",
    "video = mp.VideoFileClip(\".\\\\videos\\\\{}_{}.mp4\".format(name_file, n_file))\n",
    "audio = video.audio.write_audiofile(r\".\\\\audios\\\\{}_{}.wav\".format(name_file, n_file)) # de cuando se recibia un vídeo\n",
    "recibido_cambio = sr.Recognizer()\n",
    "speech_audio = sr.AudioFile(\".\\\\audios\\\\{}_{}.wav\".format(name_file, n_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tengo la próxima rotonda rotonda media levanto el pie del acelerador lo tonta cerca y en la ocupada\n"
     ]
    }
   ],
   "source": [
    "# Reconocedor básico\n",
    "\n",
    "with speech_audio as fuente:\n",
    "    #Se reduce el ruido\n",
    "    recibido_cambio.adjust_for_ambient_noise(fuente)\n",
    "    audio = recibido_cambio.record(fuente)\n",
    "    #Transcripcion\n",
    "    texto_transcrito = recibido_cambio.recognize_google(audio, language = \"es-ES\")\n",
    "    print(texto_transcrito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha guardado la transcripción en el archivo .\\t_raw\\Borja_7.txt\n"
     ]
    }
   ],
   "source": [
    "# Guardo el texto en bruto transcrito de los audios\n",
    "\n",
    "filename_t_raw = \".\\\\t_raw\\\\{}_{}.txt\".format(name_file, n_file)\n",
    "with open(filename_t_raw, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(texto_transcrito)\n",
    "print(\"Se ha guardado la transcripción en el archivo \" + filename_t_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('.\\\\t_processed\\\\{}_{}.txt'.format(name_file, n_file),'r',encoding='utf8')\n",
    "text = f.read()\n",
    "\n",
    "sw = set(stopwords.words(\"spanish\"))\n",
    "# Limpio con regex el texto\n",
    "text = re.sub('[%s]' % re.escape(string.punctuation + \"'\" + '\"' + \"’\" + '”' + '“' + \"•‘\"), ' ', str(text))\n",
    "text = re.sub('\\w*\\d\\w*', ' ', str(text))\n",
    "# Pongo el texto en minúsculas\n",
    "text = text.lower()\n",
    "# Tokenizo por palabras\n",
    "text = word_tokenize(str(text), language='spanish')\n",
    "tokens = []\n",
    "for t in text:\n",
    "    if not t in sw or t == 'no':\n",
    "        tokens.append(t)\n",
    "\n",
    "json_filename = \".\\\\t_processed\\\\{}_{}.json\".format(name_file, n_file)\n",
    "with open(json_filename, \"w\", encoding='utf-8') as f:\n",
    "    data = json.dump([], f)\n",
    "with open(json_filename, \"r\", encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "for t in tokens:\n",
    "    entry = {\n",
    "        'word': t,\n",
    "        'token': SnowballStemmer('spanish').stem(t),\n",
    "        'start': 0.0\n",
    "    }\n",
    "    data.append(entry)\n",
    "\n",
    "with open(json_filename, \"w\", encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrucciones = {\n",
    "    'aceler': 'T-ON',\n",
    "    'acerc rotond': 'APROX',\n",
    "    'rotond medi': 'RND-MD',\n",
    "    'manteng aceler': 'T-HOLD',\n",
    "    'rotond cerc': 'RND-NR',\n",
    "    'izquierd libr': 'L-FREE',\n",
    "    'izquierd ocup': 'L-BUSY',\n",
    "    'fren ced': 'B-ON',\n",
    "    'fren': 'B-ON',\n",
    "    'stop': 'B-ON',\n",
    "    'ced': 'RND-IN',\n",
    "    'entro rotond': 'RND-IN',\n",
    "    'gir derech': 'TURN-R',\n",
    "    'intermitent izquierd': 'LB-ON',\n",
    "    'intermitent izquierd rotond': 'LB-ON',\n",
    "    'rotond gir izquierd': 'TURN-L',\n",
    "    'rotond gir derech': 'TURN-R',\n",
    "    'gir izquierd': 'TURN-L',\n",
    "    'quit intermitent': 'BLK-OFF',\n",
    "    'intermitent derech': 'RB-ON',\n",
    "    'intermitent derech rotond': 'RB-ON',\n",
    "    'salg rotond': 'RND-EXIT',\n",
    "    'aproxim rotond': 'APROX',\n",
    "    'levant aceler': 'T-OFF',\n",
    "    'levant pie aceler': 'T-OFF',\n",
    "    'no vien nadi': 'RND-CLEAR',\n",
    "    'gir izquierd rotond': 'TURN-L',\n",
    "    'gir derech rotond': 'TURN-R',\n",
    "    'atencion ciclist': 'CAR-NR',\n",
    "    'atencion coche': 'CAR-NR',\n",
    "    'centr libr': 'L-FREE',\n",
    "    'centr ocup': 'F-BUSY',\n",
    "    'enderez': 'TURN-STR',\n",
    "    'rect': 'STR'\n",
    "}\n",
    "\n",
    "json_filename = \".\\\\t_processed\\\\{}_{}.json\".format(name_file, n_file)\n",
    "with open(json_filename, \"r\", encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dataset = {}\n",
    "count = 0\n",
    "\n",
    "for i, x in enumerate(data):\n",
    "    w = x['token']\n",
    "    if (len(data) > i + 2) and x['token'] + ' ' + data[i + 1]['token'] + ' ' + data[i + 2]['token'] in instrucciones:\n",
    "        sentence = x['word'] + ' ' + data[i + 1]['word'] + ' ' + data[i + 2]['word']\n",
    "        sentence_t = x['token'] + ' ' + data[i + 1]['token'] + ' ' + data[i + 2]['token']\n",
    "        dataset[\"inst_{}\".format(count)] = [x, data[i + 1], data[i + 2]]\n",
    "        dataset[\"inst_{}\".format(count)].append({\"tag\": instrucciones[sentence_t], \"sentence\": sentence})\n",
    "        count += 1\n",
    "        del data[i + 1]\n",
    "        del data[i + 1]\n",
    "    elif (len(data) > i + 1) and x['token'] + ' ' + data[i + 1]['token'] in instrucciones:\n",
    "        sentence = x['word'] + ' ' + data[i + 1]['word']\n",
    "        sentence_t = x['token'] + ' ' + data[i + 1]['token']\n",
    "        dataset[\"inst_{}\".format(count)] = [x, data[i + 1]]\n",
    "        dataset[\"inst_{}\".format(count)].append({\"tag\": instrucciones[sentence_t], \"sentence\": sentence})\n",
    "        count += 1\n",
    "        del data[i + 1]\n",
    "    elif x['token'] in instrucciones:\n",
    "        dataset[\"inst_{}\".format(count)] = [x]\n",
    "        dataset[\"inst_{}\".format(count)].append({\"tag\": instrucciones[w], \"sentence\": x['word']})\n",
    "        count += 1\n",
    "\n",
    "json_out = \".\\\\t_tags\\\\{}_{}.json\".format(name_file, n_file)\n",
    "with open(json_out, \"w\", encoding='utf-8') as f:\n",
    "    json.dump(dataset, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bbc1c972b9b102a93c73821bc38c3abe2659eb37faffcc2a906a1a9997853cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
