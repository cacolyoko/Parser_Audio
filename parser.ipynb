{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import speech_recognition as sr\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = \"Borja\"\n",
    "n_file = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 0/1000 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in .\\\\audios\\\\Borja_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Extraigo el audio del vídeo\n",
    "\n",
    "video = mp.VideoFileClip(\".\\\\videos\\\\{}_{}.mp4\".format(name_file, n_file))\n",
    "audio = video.audio.write_audiofile(r\".\\\\audios\\\\Borja_{}.wav\".format(name_file, n_file)) # de cuando se recibia un vídeo\n",
    "recibido_cambio = sr.Recognizer()\n",
    "speech_audio = sr.AudioFile(\".\\\\audios\\\\{}_{}.wav\".format(name_file, n_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Caco\\Desktop\\UNIVERSIDAD\\CUARTO\\TFG\\Parser_Audios\\Parser_Audio\\parser.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Caco/Desktop/UNIVERSIDAD/CUARTO/TFG/Parser_Audios/Parser_Audio/parser.ipynb#ch0000002?line=5'>6</a>\u001b[0m audio \u001b[39m=\u001b[39m recibido_cambio\u001b[39m.\u001b[39mrecord(fuente)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Caco/Desktop/UNIVERSIDAD/CUARTO/TFG/Parser_Audios/Parser_Audio/parser.ipynb#ch0000002?line=6'>7</a>\u001b[0m \u001b[39m#Transcripcion\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Caco/Desktop/UNIVERSIDAD/CUARTO/TFG/Parser_Audios/Parser_Audio/parser.ipynb#ch0000002?line=7'>8</a>\u001b[0m texto_transcrito \u001b[39m=\u001b[39m recibido_cambio\u001b[39m.\u001b[39;49mrecognize_google(audio, language \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mes-ES\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Caco/Desktop/UNIVERSIDAD/CUARTO/TFG/Parser_Audios/Parser_Audio/parser.ipynb#ch0000002?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(texto_transcrito)\n",
      "File \u001b[1;32mc:\\Users\\Caco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\speech_recognition\\__init__.py:858\u001b[0m, in \u001b[0;36mRecognizer.recognize_google\u001b[1;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[39m# return results\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[39mif\u001b[39;00m show_all: \u001b[39mreturn\u001b[39;00m actual_result\n\u001b[1;32m--> 858\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(actual_result, \u001b[39mdict\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(actual_result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m, [])) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mraise\u001b[39;00m UnknownValueError()\n\u001b[0;32m    860\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m actual_result[\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    861\u001b[0m     \u001b[39m# return alternative with highest confidence score\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     best_hypothesis \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(actual_result[\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m], key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m alternative: alternative[\u001b[39m\"\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reconocedor básico\n",
    "\n",
    "with speech_audio as fuente:\n",
    "    #Se reduce el ruido\n",
    "    recibido_cambio.adjust_for_ambient_noise(fuente)\n",
    "    audio = recibido_cambio.record(fuente)\n",
    "    #Transcripcion\n",
    "    texto_transcrito = recibido_cambio.recognize_google(audio, language = \"es-ES\")\n",
    "    print(texto_transcrito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha guardado la transcripción en el archivo .\\t_raw\\Borja_1.txt\n"
     ]
    }
   ],
   "source": [
    "# Guardo el texto en bruto transcrito de los audios\n",
    "\n",
    "filename_t_raw = \".\\\\t_raw\\\\{}_{}.txt\".format(name_file, n_file)\n",
    "with open(filename_t_raw, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(texto_transcrito)\n",
    "print(\"Se ha guardado la transcripción en el archivo \" + filename_t_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'aproxim', 'start': 0.0, 'end': 0.0}, {'word': 'rotond', 'start': 0.0, 'end': 0.0}, {'word': 'aceler', 'start': 0.0, 'end': 0.0}, {'word': 'levant', 'start': 0.0, 'end': 0.0}, {'word': 'pie', 'start': 0.0, 'end': 0.0}, {'word': 'aceler', 'start': 0.0, 'end': 0.0}, {'word': 'rotond', 'start': 0.0, 'end': 0.0}, {'word': 'medi', 'start': 0.0, 'end': 0.0}, {'word': 'rotond', 'start': 0.0, 'end': 0.0}, {'word': 'cerc', 'start': 0.0, 'end': 0.0}, {'word': 'manteg', 'start': 0.0, 'end': 0.0}, {'word': 'aceler', 'start': 0.0, 'end': 0.0}, {'word': 'izquierd', 'start': 0.0, 'end': 0.0}, {'word': 'libr', 'start': 0.0, 'end': 0.0}, {'word': 'vien', 'start': 0.0, 'end': 0.0}, {'word': 'nadi', 'start': 0.0, 'end': 0.0}, {'word': 'entro', 'start': 0.0, 'end': 0.0}, {'word': 'rotond', 'start': 0.0, 'end': 0.0}, {'word': 'gir', 'start': 0.0, 'end': 0.0}, {'word': 'izquierd', 'start': 0.0, 'end': 0.0}, {'word': 'rotond', 'start': 0.0, 'end': 0.0}, {'word': 'manteng', 'start': 0.0, 'end': 0.0}, {'word': 'aceler', 'start': 0.0, 'end': 0.0}, {'word': 'gir', 'start': 0.0, 'end': 0.0}, {'word': 'izquierd', 'start': 0.0, 'end': 0.0}, {'word': 'atencion', 'start': 0.0, 'end': 0.0}, {'word': 'ciclist', 'start': 0.0, 'end': 0.0}, {'word': 'fren', 'start': 0.0, 'end': 0.0}, {'word': 'aceler', 'start': 0.0, 'end': 0.0}, {'word': 'manteng', 'start': 0.0, 'end': 0.0}, {'word': 'aceler', 'start': 0.0, 'end': 0.0}, {'word': 'gir', 'start': 0.0, 'end': 0.0}, {'word': 'derech', 'start': 0.0, 'end': 0.0}, {'word': 'salg', 'start': 0.0, 'end': 0.0}, {'word': 'rotond', 'start': 0.0, 'end': 0.0}, {'word': 'aceler', 'start': 0.0, 'end': 0.0}, {'word': 'aceler', 'start': 0.0, 'end': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "f = open ('.\\\\t_processed\\\\{}_{}.txt'.format(name_file, n_file),'r',encoding='utf8')\n",
    "text = f.read()\n",
    "\n",
    "sw = set(stopwords.words(\"spanish\"))\n",
    "# Limpio con regex el texto\n",
    "text = re.sub('[%s]' % re.escape(string.punctuation + \"'\" + '\"' + \"’\" + '”' + '“' + \"•‘\"), ' ', str(text))\n",
    "text = re.sub('\\w*\\d\\w*', ' ', str(text))\n",
    "# Pongo el texto en minúsculas\n",
    "text = text.lower()\n",
    "# Tokenizo por palabras\n",
    "text = word_tokenize(str(text), language='spanish')\n",
    "tokens = []\n",
    "for t in text:\n",
    "    if not t in sw:\n",
    "        tokens.append(t)\n",
    "\n",
    "json_filename = \".\\\\t_processed\\\\{}_{}.json\".format(name_file, n_file)\n",
    "with open(json_filename, \"w\", encoding='utf-8') as f:\n",
    "    data = json.dump({}, f)\n",
    "with open(json_filename, \"r\", encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "for t in tokens:\n",
    "    entry = {\n",
    "        'word': SnowballStemmer('spanish').stem(t),\n",
    "        'start': 0.0\n",
    "    }\n",
    "    data.append(entry)\n",
    "\n",
    "with open(json_filename, \"w\", encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RNDBT-FAR': [{'word': 'aproxim', 'start': 0.0, 'end': 0.0}, {'word': 'rotond', 'start': 0.0, 'end': 0.0}], 'ACEL-ON': [{'word': 'aceler', 'start': 0.0, 'end': 0.0}], 'ACEL-OFF': [{'word': 'levant', 'start': 0.0, 'end': 0.0}, {'word': 'pie', 'start': 0.0, 'end': 0.0}, {'word': 'aceler', 'start': 0.0, 'end': 0.0}], 'RNDBT-MED': [{'word': 'rotond', 'start': 0.0, 'end': 0.0}, {'word': 'medi', 'start': 0.0, 'end': 0.0}], 'RNDBT-NEAR': [{'word': 'rotond', 'start': 0.0, 'end': 0.0}, {'word': 'cerc', 'start': 0.0, 'end': 0.0}], 'RNDBT-CLEAR': [{'word': 'vien', 'start': 0.0, 'end': 0.0}, {'word': 'nadi', 'start': 0.0, 'end': 0.0}], 'RNDBT-IN': [{'word': 'entro', 'start': 0.0, 'end': 0.0}, {'word': 'rotond', 'start': 0.0, 'end': 0.0}], 'TURN-L': [{'word': 'gir', 'start': 0.0, 'end': 0.0}, {'word': 'izquierd', 'start': 0.0, 'end': 0.0}], 'WARN-VEH': [{'word': 'atencion', 'start': 0.0, 'end': 0.0}, {'word': 'ciclist', 'start': 0.0, 'end': 0.0}], 'BRK': [{'word': 'fren', 'start': 0.0, 'end': 0.0}], 'TURN-R': [{'word': 'gir', 'start': 0.0, 'end': 0.0}, {'word': 'derech', 'start': 0.0, 'end': 0.0}], 'RNDBT-OUT': [{'word': 'salg', 'start': 0.0, 'end': 0.0}, {'word': 'rotond', 'start': 0.0, 'end': 0.0}]}\n"
     ]
    }
   ],
   "source": [
    "instrucciones = {\n",
    "    'aceler': 'ACEL-ON',\n",
    "    'acerc rotond': 'RNDBT-FAR',\n",
    "    'rotond medi': 'RNDBT-MED',\n",
    "    'manteng aceler': 'ACEL-ON',\n",
    "    'rotond cerc': 'RNDBT-NEAR',\n",
    "    'izquierd libr': 'RNDBT-CLEAR',\n",
    "    'ced': 'CEDA',\n",
    "    'entro rotond': 'RNDBT-IN',\n",
    "    'gir derech': 'TURN-R',\n",
    "    'intermitent izquierd': 'BLK-L',\n",
    "    'rotond gir izquierd': 'TURN-L',\n",
    "    'rotond gir derech': 'TURN-R',\n",
    "    'gir izquierd': 'TURN-L',\n",
    "    'quit intermitent': 'BLK-OFF',\n",
    "    'intermitent derech': 'BLK-R',\n",
    "    'salg rotond': 'RNDBT-OUT',\n",
    "    'aproxim rotond': 'RNDBT-FAR',\n",
    "    'levant pie aceler': 'ACEL-OFF',\n",
    "    'vien nadi': 'RNDBT-CLEAR',\n",
    "    'gir izquierd rotond': 'TURN-L',\n",
    "    'gir derech rotond': 'TURN-R',\n",
    "    'atencion ciclist': 'WARN-VEH',\n",
    "    'fren': 'BRK'\n",
    "}\n",
    "\n",
    "json_filename = \".\\\\t_processed\\\\{}_{}.json\".format(name_file, n_file)\n",
    "with open(json_filename, \"r\", encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for i, x in enumerate(data):\n",
    "    w = x['word']\n",
    "    if x['word'] in instrucciones:\n",
    "        #print(\"{} => {}\".format(w, instrucciones[w]))\n",
    "        dataset[instrucciones[w]] = [x]\n",
    "    elif (len(data) > i + 2) and x['word'] + ' ' + data[i + 1]['word'] + ' ' + data[i + 2]['word'] in instrucciones:\n",
    "        sentence = x['word'] + ' ' + data[i + 1]['word'] + ' ' + data[i + 2]['word']\n",
    "        dataset[instrucciones[sentence]] = [x, data[i + 1], data[i + 2]]\n",
    "        #print(\"{} => {}\".format(sentence, instrucciones[sentence]))\n",
    "    elif (len(data) > i + 1) and x['word'] + ' ' + data[i + 1]['word'] in instrucciones:\n",
    "        sentence = x['word'] + ' ' + data[i + 1]['word']\n",
    "        dataset[instrucciones[sentence]] = [x, data[i + 1]]\n",
    "        #print(\"{} => {}\".format(sentence, instrucciones[sentence]))\n",
    "\n",
    "json_out = \".\\\\t_tags\\\\{}_{}.json\".format(name_file, n_file)\n",
    "with open(json_out, \"w\") as f:\n",
    "    json.dump(dataset, f, ensure_ascii=False)\n",
    "\n",
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bbc1c972b9b102a93c73821bc38c3abe2659eb37faffcc2a906a1a9997853cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
